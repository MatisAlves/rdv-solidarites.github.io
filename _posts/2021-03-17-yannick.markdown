---
layout: post
title:  "Journal de Yannick"
date:   2021-03-17
---

Point sur les PR en cours

## Réunion sur le produit et priorisation

* Un peu de méta sur les rituels et la documentation liée, sur la forme des tickets
* Sur les modalités du rituel de cette réunion
* Échange sur l'atelier Cellule Familiale et les pistes à suivre pour agir.

Nous n'arrivons pas vraiment à conclure sur une orientation.

Point avec l'équipe Data.insertion. Nous discutons de l'unicité des usagers. Je prends conscience qu'ils n'utilisent pas de base de donnée, ou plutôt que RDV-Solidarités est la base de données. Je crois que nous arrivons à la limite. Faut-il dupliquer les `users` dans ces applications diverses ?.

Nous discutons d'un schéma que Nicolas a réalisé. C'est assez clair. Il reste un nom à trouver. Et sans doute il faudra définir quelle brique mettre.

## Travaux pour la résolution du ticket \#1427

[Afficher le bloc de statistique des rendez-vous par statuts \#1427](https://github.com/betagouv/rdv-solidarites.fr/issues/1427) 

Je me casse un peu les dents sur la reproduction. Du coup, je repars dans l'exploration d'optimisation de la requête. C'est la seule qui utilise des manipulations ruby en plus d'ActiveRecord. J'en déduis que c'est donc elle qui pose problème.

Reste une question, pourquoi avec mes 70 000 RDV je n'ai pas de soucis alors qu'en démo, avec 1575 il y a un problème ?

Est-ce le timeout Scalingo qui est plus court que celui de mon environnement de dev ?

Sans doute. Les pistes sont : faire un diagramme autrement, sans pourcentage \(et sans traduction des status :-/\), réduire le scope en prenant uniquement les 3 derniers mois ou en faisant une somme de tous les rdvs, sans répartition par mois, voir faire le calcul de % dans la requête SQL  [https://stackoverflow.com/questions/35334751/calculating-percentage-value-for-a-group-by-value-in-postgres\#35335272](https://stackoverflow.com/questions/35334751/calculating-percentage-value-for-a-group-by-value-in-postgres#35335272)

Pour le problème de tableau de stat, je me demande s'il n'y a pas aussi un souci de quantité \(taille de fichier, nombre d'entrées\). Je devrais peut-être reprendre un script de génération de rdv avec une très grande amplitude de temps. Il est peut-être temps de récupérer les bases de prod pour voir.

